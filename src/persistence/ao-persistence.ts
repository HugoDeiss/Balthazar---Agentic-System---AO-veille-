// src/persistence/ao-persistence.ts
import { createClient, SupabaseClient } from '@supabase/supabase-js';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ”§ CLIENT SUPABASE
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

let supabaseClient: SupabaseClient | null = null;

/**
 * RÃ©cupÃ¨re ou crÃ©e le client Supabase
 * RÃ©utilise la mÃªme instance pour Ã©viter les reconnexions
 */
function getSupabaseClient(): SupabaseClient {
  if (!supabaseClient) {
    const url = process.env.SUPABASE_URL;
    const key = process.env.SUPABASE_SERVICE_KEY;
    
    if (!url || !key) {
      throw new Error('SUPABASE_URL et SUPABASE_SERVICE_KEY doivent Ãªtre dÃ©finis dans les variables d\'environnement');
    }
    
    supabaseClient = createClient(url, key);
  }
  
  return supabaseClient;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ”„ UTILITAIRES DE CONVERSION
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Convertit une date string (YYYY-MM-DD) en timestamp ISO pour Supabase
 * Si la date est null, retourne null
 */
function toTimestamp(dateString: string | null): string | null {
  if (!dateString) return null;
  
  // Si c'est dÃ©jÃ  un timestamp ISO, on le retourne tel quel
  if (dateString.includes('T')) {
    return dateString;
  }
  
  // Sinon, on convertit YYYY-MM-DD en timestamp ISO
  // On utilise minuit UTC pour Ã©viter les problÃ¨mes de timezone
  const date = new Date(`${dateString}T00:00:00.000Z`);
  
  if (isNaN(date.getTime())) {
    console.warn(`âš ï¸ Date invalide: ${dateString}, retour null`);
    return null;
  }
  
  return date.toISOString();
}

/**
 * DÃ©duplique un tableau de strings
 */
function uniq(arr: string[]): string[] {
  return Array.from(new Set(arr));
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ” VÃ‰RIFICATION D'ANALYSE
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * VÃ©rifie si un AO est dÃ©jÃ  analysÃ© (status = 'analyzed' avec analyzed_at)
 * UtilisÃ© pour Ã©viter de re-analyser les AO lors des retries
 * 
 * @param source - Source de l'AO ('BOAMP')
 * @param sourceId - ID source de l'AO
 * @returns true si l'AO est dÃ©jÃ  analysÃ©, false sinon
 */
export async function isAOAlreadyAnalyzed(source: string, sourceId: string): Promise<boolean> {
  const supabase = getSupabaseClient();
  
  const { data, error } = await supabase
    .from('appels_offres')
    .select('id, status, analyzed_at')
    .eq('source', source)
    .eq('source_id', sourceId)
    .maybeSingle();
  
  if (error) {
    // Si erreur autre que "not found", on log mais on considÃ¨re comme non analysÃ©
    if (error.code !== 'PGRST116') { // PGRST116 = no rows returned
      console.warn(`âš ï¸ Erreur vÃ©rification AO ${sourceId}:`, error);
    }
    return false; // En cas d'erreur, on considÃ¨re comme non analysÃ© (sÃ©curitÃ©)
  }
  
  // L'AO est dÃ©jÃ  analysÃ© si :
  // 1. Il existe en base
  // 2. Son status est 'analyzed'
  // 3. Il a un analyzed_at (date d'analyse)
  if (data && data.status === 'analyzed' && data.analyzed_at) {
    return true;
  }
  
  return false;
}

/**
 * VÃ©rifie en batch quels AO sont dÃ©jÃ  analysÃ©s (optimisation)
 * Une seule requÃªte DB au lieu de N requÃªtes individuelles
 * 
 * @param aos - Tableau d'AO avec source et source_id
 * @returns Map<source_id, boolean> indiquant si chaque AO est dÃ©jÃ  analysÃ©
 */
export async function checkBatchAlreadyAnalyzed(
  aos: Array<{ source: string; source_id: string }>
): Promise<Map<string, boolean>> {
  const supabase = getSupabaseClient();
  const result = new Map<string, boolean>();
  
  if (aos.length === 0) {
    return result;
  }
  
  // RÃ©cupÃ©rer tous les source_id uniques
  const sourceIds = [...new Set(aos.map(ao => ao.source_id))];
  const source = aos[0]?.source || 'BOAMP'; // Tous les AO ont la mÃªme source
  
  // RequÃªte batch : rÃ©cupÃ©rer tous les AO dÃ©jÃ  analysÃ©s pour ces source_id
  const { data, error } = await supabase
    .from('appels_offres')
    .select('source_id, status, analyzed_at')
    .eq('source', source)
    .in('source_id', sourceIds)
    .eq('status', 'analyzed')
    .not('analyzed_at', 'is', null);
  
  if (error) {
    console.warn(`âš ï¸ Erreur vÃ©rification batch AO:`, error);
    // En cas d'erreur, on considÃ¨re tous comme non analysÃ©s (sÃ©curitÃ©)
    sourceIds.forEach(id => result.set(id, false));
    return result;
  }
  
  // Construire la map : source_id -> true si analysÃ©
  const analyzedIds = new Set((data || []).map(ao => ao.source_id));
  
  // Initialiser tous Ã  false, puis marquer ceux qui sont analysÃ©s
  aos.forEach(ao => {
    result.set(ao.source_id, analyzedIds.has(ao.source_id));
  });
  
  return result;
}

